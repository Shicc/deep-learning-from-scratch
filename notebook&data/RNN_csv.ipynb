{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# tf.set_random_seed(1)\n",
    "# np.random.seed(1)\n",
    "print('1111')\n",
    "\n",
    "def to_onehot(y):\n",
    "    for i in range(len(y)):\n",
    "        if y.iloc[i,0]==0:\n",
    "            y.iloc[i,0] = 'y'\n",
    "        else:\n",
    "            y.iloc[i,0] = 'f'\n",
    "    return pd.get_dummies(y,prefix=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "# 参数，超参数\n",
    "batch_size = 50\n",
    "time_step = 40\n",
    "input_size = 40\n",
    "lr = 0.5\n",
    "print('1111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "train_data_set = pd.read_csv('train.csv')                   # shape:(4000,1602)\n",
    "train_data = train_data_set.iloc[0:4000,1:1601]             # shape:(4000,1600)\n",
    "train_labels = to_onehot(train_data_set.iloc[0:4000,[1601]])            # shape:(4000,1)\n",
    "print('1111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "# 选择部分数据集\n",
    "test_data_set = pd.read_csv('test.csv')                # shape:(3550,1601) 没有包含正确结果，和训练集不一样\n",
    "test_data = test_data_set.iloc[0:1000,1:1601]           # shape:(1000,1600)\n",
    "test_labels = to_onehot(\n",
    "    pd.read_csv('sample_submit.csv').iloc[0:1000,[1]])          # shape:(1000,1) 一一对应\n",
    "print('1111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\program files\\python\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "1111\n"
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "tf_x = tf.placeholder(tf.float32,[None,time_step*input_size])\n",
    "x_img = tf.reshape(tf_x,[-1,time_step,input_size])\n",
    "tf_y = tf.placeholder(tf.int32,[None,2])\n",
    "\n",
    "## RNN\n",
    "rnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units = 50)\n",
    "output_ , states = tf.nn.dynamic_rnn(\n",
    "        rnn_cell,               #cell\n",
    "        x_img,                  #input\n",
    "        initial_state = None,   #初始化隐藏层的状态？表示不初始化？\n",
    "        dtype = tf.float32,     #和上面那句必须同时出现\n",
    "        time_major = False      #False: (batch, time_step, input); True: (time_step, batch, input)\n",
    ")\n",
    "output = tf.layers.dense(output_[:,-1,:],2) #对输出进行最后的修改\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=tf_y,logits = output)\n",
    "train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "# 计算精度\n",
    "# 计算精度\n",
    "accuracy = tf.metrics.accuracy(\n",
    "        labels = tf.argmax(tf_y,axis = 1),\n",
    "        predictions = tf.argmax(output,axis = 1)\n",
    ")[1]\n",
    "print('1111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init_op)\n",
    "print('1111')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | train loss: 3.4960 | test accuracy: 0.50222224\n",
      "Step: 50 | train loss: 0.7562 | test accuracy: 0.50199997\n",
      "Step: 100 | train loss: 0.0000 | test accuracy: 0.50181818\n",
      "Step: 150 | train loss: 0.0000 | test accuracy: 0.50166667\n",
      "Step: 200 | train loss: 0.0000 | test accuracy: 0.50153846\n",
      "Step: 250 | train loss: 0.0000 | test accuracy: 0.50142854\n",
      "predictions_2: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0] output: [[ 9.10906982 -9.22535992]\n",
      " [ 9.10906982 -9.22535992]\n",
      " [ 9.10906982 -9.22535992]\n",
      " ..., \n",
      " [ 9.10906982 -9.22535992]\n",
      " [ 9.10906982 -9.22535992]\n",
      " [ 9.10906982 -9.22535992]]\n",
      "Step: 300 | train loss: 0.0000 | test accuracy: 0.50133336\n",
      "Step: 350 | train loss: 0.0000 | test accuracy: 0.50125003\n"
     ]
    }
   ],
   "source": [
    "for step in range(351):\n",
    "    b_x = train_data.iloc[step*batch_size:(step+1)*batch_size]\n",
    "    b_y = train_labels.iloc[step*batch_size:(step+1)*batch_size]\n",
    "    _,loss_ = sess.run([train_op,loss],feed_dict = {tf_x:b_x,tf_y:b_y})\n",
    "    if step % batch_size ==0:\n",
    "        accuracy_= sess.run(accuracy,feed_dict = {tf_x:test_data,tf_y:test_labels})\n",
    "        print('Step:', step,'| train loss: %.4f' % loss_, '| test accuracy: %.8f' % accuracy_)\n",
    "    if step == 299:\n",
    "        predictions_2 = tf.argmax(output,axis = 1)\n",
    "        test_data_ = test_data\n",
    "        predictions_2_ ,output_= sess.run([predictions_2,output], feed_dict = {tf_x: test_data_})\n",
    "        print('predictions_2:', predictions_2_,'output:',output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
