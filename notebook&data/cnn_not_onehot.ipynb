{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 准备训练数据\n",
    "train_data_set = pd.read_csv('train.csv')\n",
    "# 获取训练集输入数据\n",
    "train_data = train_data_set.iloc[0:4000,1:1601]\n",
    "# 获取训练集的正确标签\n",
    "train_labels = train_data_set.iloc[0:4000,[1601]]\n",
    "#准备测试数据\n",
    "test_data_set = pd.read_csv('test.csv')\n",
    "## 可以查看一下矩阵的维度，方便处理数据\n",
    "# print(test_data.shape)\n",
    "test_data = test_data_set.iloc[0:3550,1:1601]\n",
    "test_labels = pd.read_csv('sample_submit.csv').iloc[0:3550,[1]]\n",
    "print(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50  # 一批取50个数据\n",
    "lr = 0.05       # learning rate\n",
    "\n",
    "test_data_set = pd.read_csv('test.csv')                 # shape:(3550,1601) 没有包含正确结果，和训练集不一样\n",
    "test_data = test_data_set.iloc[0:1000,1:1601]           # shape:(1000,1600)\n",
    "test_labels = pd.read_csv(\n",
    "        'sample_submit.csv').iloc[0:1000,[1]]           # shape:(1000,1) 一一对应\n",
    "print(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# 创建模型\n",
    "tf_x = tf.placeholder(tf.float32,[None,40*40])   # 每批50个数据，此处暂时不管，为None\n",
    "x_img = tf.reshape(tf_x,[-1,40,40,1])            # (batch, height, width, channel)\n",
    "tf_y = tf.placeholder(tf.float32,[None,1])\n",
    "## CNN\n",
    "## 激励函数此处选择的是relu\n",
    "conv1 = tf.layers.conv2d(           # shape:(40,40,1)\n",
    "        inputs = x_img,\n",
    "        filters = 10,               # 图像卷积后的深度\n",
    "        kernel_size = 5,            # 扫描核5*5大小\n",
    "        strides = 1,\n",
    "        padding = 'same',\n",
    "        activity_regularizer = tf.nn.relu\n",
    ")                                   # shape:(40,40,10)\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "        inputs = conv1,\n",
    "        pool_size = 2,\n",
    "        strides = 2\n",
    ")                                   # shape:(20,20,10)\n",
    "conv2 = tf.layers.conv2d(\n",
    "        inputs = pool1,\n",
    "        filters = 20,\n",
    "        kernel_size = 5,\n",
    "        strides = 1,\n",
    "        padding = 'same',\n",
    "        activity_regularizer = tf.nn.relu\n",
    ")                                   # shape:(20,20,20)\n",
    "pool2 = tf.layers.max_pooling2d(\n",
    "        inputs = conv2,\n",
    "        pool_size = 2,\n",
    "        strides = 2\n",
    ")                                   # shape:(10,10,20)\n",
    "flat_data = tf.reshape(pool2,[-1,10*10*20]) #(10*10*20, )\n",
    "output = tf.layers.dense(flat_data,1) #用于全连接层，二分类0或者1。输出为某一种特定的类型。\n",
    "print(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "# loss = tf.losses.softmax_cross_entropy(tf_y,logits = output)\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(tf_y * tf.log(output + 1e-10),reduction_indices=[1]))\n",
    "train_op = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "\n",
    "# 用于测试改模型的识别精确度\n",
    "accuracy = tf.metrics.accuracy(\n",
    "        labels = tf_y,\n",
    "        predictions = output\n",
    ")[1]\n",
    "print(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# 初始化全局和本地变量\n",
    "init_op = tf.group(\n",
    "        tf.global_variables_initializer(), \n",
    "        tf.local_variables_initializer())\n",
    "sess.run(init_op)\n",
    "print(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | test accuracy: 0.00000000\n",
      "Step: 50 | test accuracy: 0.00000000\n",
      "Step: 100 | test accuracy: 0.00000000\n",
      "Step: 150 | test accuracy: 0.00000000\n",
      "Step: 200 | test accuracy: 0.00000000\n",
      "Step: 250 | test accuracy: 0.00000000\n",
      "Step: 300 | test accuracy: 0.00000000\n",
      "Step: 350 | test accuracy: 0.00000000\n",
      "Step: 400 | test accuracy: 0.00000000\n",
      "Step: 450 | test accuracy: 0.00000000\n",
      "Step: 500 | test accuracy: 0.00000000\n",
      "Step: 550 | test accuracy: 0.00000000\n",
      "Step: 600 | test accuracy: 0.00000000\n",
      "Step: 650 | test accuracy: 0.00000000\n",
      "Step: 700 | test accuracy: 0.00000000\n",
      "Step: 750 | test accuracy: 0.00000000\n",
      "Step: 800 | test accuracy: 0.00000000\n",
      "Step: 850 | test accuracy: 0.00000000\n",
      "Step: 900 | test accuracy: 0.00000000\n",
      "Step: 950 | test accuracy: 0.00000000\n",
      "Step: 1000 | test accuracy: 0.00000000\n"
     ]
    }
   ],
   "source": [
    "# 训练，每批50个数据，一共4000个，80批一次数据集循环\n",
    "for step in range(1001):                        # step = 0~999,一共1000个\n",
    "    b_x = train_data.iloc[step*batch_size:(step+1)*batch_size]  # 取批数据\n",
    "    b_y = train_labels.iloc[step*batch_size:(step+1)*batch_size]\n",
    "    sess.run(train_op,feed_dict = {tf_x:b_x,tf_y:b_y})\n",
    "    if step % batch_size ==0:\n",
    "        accuracy_= sess.run(accuracy,feed_dict = {tf_x:test_data,tf_y:test_labels})\n",
    "        print('Step:', step,'| test accuracy: %.8f' % accuracy_)\n",
    "    \n",
    "    if step == 990:\n",
    "        test_data_ = test_data.iloc[23:167]\n",
    "        output_= sess.run(output, feed_dict = {tf_x: test_data_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o1: -246711.90625000\n",
      "o2: -246711.90625000\n",
      "o3: -240683.0\n",
      "o3的类型 <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "o1 = output_[0][0]\n",
    "print('o1: %.8f' % o1)\n",
    "\n",
    "o2 = output_[0]\n",
    "print('o2: %.8f' % o2)\n",
    "\n",
    "o3 = output_[1][0]\n",
    "print('o3:',o3)\n",
    "print('o3的类型',type(o3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
