{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "# import numpy as np\n",
    "\n",
    "# tf.set_random_seed(1)\n",
    "# np.random.seed(1)\n",
    "\n",
    "# 参数，超参数\n",
    "batch_size = 50\n",
    "lr = 0.5\n",
    "\n",
    "def to_onehot(y):\n",
    "    for i in range(len(y)):\n",
    "        if y.iloc[i,0]==0:\n",
    "            y.iloc[i,0] = 'y'\n",
    "        else:\n",
    "            y.iloc[i,0] = 'f'\n",
    "    return pd.get_dummies(y,prefix=y.columns)\n",
    "\n",
    "# 准备数据\n",
    "train_data_set = pd.read_csv('train.csv')                   # shape:(4000,1602)\n",
    "train_data = train_data_set.iloc[0:4000,1:1601]       # shape:(4000,1600)\n",
    "train_labels = to_onehot(train_data_set.iloc[0:4000,[1601]])           # shape:(4000,1)\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n"
     ]
    }
   ],
   "source": [
    "# 先取一小批测试数据看看结果\n",
    "test_data_set = pd.read_csv('test.csv')                 # shape:(3550,1601) 没有包含正确结果，和训练集不一样\n",
    "test_data = test_data_set.iloc[0:1000,1:1601]           # shape:(1000,1600)\n",
    "test_labels = to_onehot(\n",
    "    pd.read_csv('sample_submit.csv').iloc[0:1000,[1]])          # shape:(1000,1) 一一对应\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\program files\\python\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "# 创建模型\n",
    "tf_x = tf.placeholder(tf.float32,[None,40*40])          # 每批50个数据，此处暂时不管，为None\n",
    "x_img = tf.reshape(tf_x,[-1,40,40,1])                   # (batch, height, width, channel)\n",
    "tf_y = tf.placeholder(tf.float32,[None,2])\n",
    "\n",
    "## CNN\n",
    "conv1 = tf.layers.conv2d(           # shape:(40,40,8)\n",
    "        inputs = x_img,\n",
    "        filters = 10,               # 图像卷积后的深度\n",
    "        kernel_size = 5,            # 扫描核5*5大小\n",
    "        strides = 1,\n",
    "        padding = 'same',\n",
    "        activity_regularizer = tf.nn.relu\n",
    ")                                   # shape:(40,40,10)\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "        inputs = conv1,\n",
    "        pool_size = 2,\n",
    "        strides = 2\n",
    ")                                   # shape:(20,20,10)\n",
    "conv2 = tf.layers.conv2d(\n",
    "        inputs = pool1,\n",
    "        filters = 20,\n",
    "        kernel_size = 5,\n",
    "        strides = 1,\n",
    "        padding = 'same',\n",
    "        activity_regularizer = tf.nn.relu\n",
    ")                                   # shape:(20,20,20)\n",
    "pool2 = tf.layers.max_pooling2d(\n",
    "        inputs = conv2,\n",
    "        pool_size = 2,\n",
    "        strides = 2\n",
    ")                                   # shape:(10,10,20)\n",
    "flat_data = tf.reshape(pool2,[-1,10*10*20]) #(10*10*20, )\n",
    "output = tf.layers.dense(flat_data,2) #用于全连接层，一共输出两种分类个数\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=tf_y,logits = output)\n",
    "# loss = tf.reduce_mean(-tf.reduce_sum(tf_y * tf.log(output),reduction_indices=[1]))\n",
    "train_op = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n"
     ]
    }
   ],
   "source": [
    "# 计算精度\n",
    "# 计算精度\n",
    "accuracy = tf.metrics.accuracy(\n",
    "        labels = tf.argmax(tf_y,axis = 1),\n",
    "        predictions = tf.argmax(output,axis = 1)\n",
    ")[1]\n",
    "\n",
    "# 重要步骤！！初始化\n",
    "sess = tf.Session()\n",
    "#初始化全局和本地变量\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "sess.run(init_op)\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 | test accuracy: 0.50000000\n",
      "Step: 200 | test accuracy: 0.50000000\n",
      "Step: 400 | test accuracy: 0.50000000\n",
      "Step: 600 | test accuracy: 0.50000000\n",
      "Step: 800 | test accuracy: 0.50000000\n",
      "Step: 1000 | test accuracy: 0.50000000\n",
      "predictions_2: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] output: [[ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]\n",
      " [ nan  nan]]\n"
     ]
    }
   ],
   "source": [
    "for step in range(1001):\n",
    "    b_x = train_data.iloc[step*batch_size:(step+1)*batch_size]\n",
    "    b_y = train_labels.iloc[step*batch_size:(step+1)*batch_size]\n",
    "    # _,loss_ = sess.run([train_op,loss],feed_dict = {tf_x:b_x,tf_y:b_y})\n",
    "    sess.run(train_op,feed_dict = {tf_x:b_x,tf_y:b_y})\n",
    "    if step % 200 ==0:\n",
    "        accuracy_= sess.run(accuracy,feed_dict = {tf_x:test_data,tf_y:test_labels})\n",
    "        print('Step:', step,'| test accuracy: %.8f' % accuracy_)\n",
    "    if step == 1000:\n",
    "        predictions_2 = tf.argmax(output,axis = 1)\n",
    "        test_data_ = test_data.iloc[23:167]\n",
    "        predictions_2_ ,output_= sess.run([predictions_2,output], feed_dict = {tf_x: test_data_})\n",
    "        print('predictions_2:', predictions_2_,'output:',output_)\n",
    "        \n",
    "#当第一次运行完了后，就可以注释掉保存的网络了。\n",
    "# 改参数可以在这里改，然后保存的模型位置又需要换一个，以免覆盖以前的。\n",
    "#   保存网络\n",
    "# saver = tf.train.Saver()\n",
    "# save_path = saver.save(sess,\"my_net/cnn_net.ckpt\",write_meta_graph = False)\n",
    "# print(\"save_path:\",save_path) #打印出来看看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y\n",
      "0   1\n",
      "1   0\n",
      "2   1\n",
      "3   0\n",
      "4   1\n",
      "5   0\n",
      "6   1\n",
      "7   0\n",
      "8   1\n",
      "9   0\n",
      "10  1\n",
      "11  0\n",
      "12  1\n",
      "13  0\n",
      "14  1\n",
      "15  0\n",
      "16  1\n",
      "17  0\n",
      "18  1\n",
      "19  0\n",
      "20  1\n",
      "21  0\n",
      "22  1\n",
      "23  0\n",
      "24  1\n",
      "25  0\n",
      "26  1\n",
      "27  0\n",
      "28  1\n",
      "29  0\n",
      "30  1\n",
      "31  0\n",
      "32  1\n",
      "33  0\n",
      "34  1\n",
      "35  0\n",
      "36  1\n",
      "37  0\n",
      "38  1\n",
      "39  0\n",
      "40  1\n",
      "41  0\n",
      "42  1\n",
      "43  0\n",
      "44  1\n",
      "45  0\n",
      "46  1\n",
      "47  0\n",
      "48  1\n",
      "49  0\n"
     ]
    }
   ],
   "source": [
    "b_y = test_labels.iloc[0:batch_size]\n",
    "print(b_y)\n",
    "# print(b_y.columns)\n",
    "b_y.to_csv(\"b_y.csv\",\n",
    "          index=False,header=False\n",
    "          )\n",
    "# b_y_onehot = pd.get_dummies(b_y,prefix=b_y.columns)\n",
    "# print(b_y_onehot)\n",
    "# print('b_y[0,0]',train_labels.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y_label\n",
      "0         1\n",
      "1         0\n",
      "2         1\n",
      "3         0\n",
      "4         1\n",
      "5         0\n",
      "6         1\n",
      "7         0\n",
      "8         1\n",
      "9         0\n",
      "10        1\n",
      "11        0\n",
      "12        1\n",
      "13        0\n",
      "14        1\n",
      "15        0\n",
      "16        1\n",
      "17        0\n",
      "18        1\n",
      "19        0\n",
      "20        1\n",
      "21        0\n",
      "22        1\n",
      "23        0\n",
      "24        1\n",
      "25        0\n",
      "26        1\n",
      "27        0\n",
      "28        1\n",
      "29        0\n",
      "30        1\n",
      "31        0\n",
      "32        1\n",
      "33        0\n",
      "34        1\n",
      "35        0\n",
      "36        1\n",
      "37        0\n",
      "38        1\n",
      "39        0\n",
      "40        1\n",
      "41        0\n",
      "42        1\n",
      "43        0\n",
      "44        1\n",
      "45        0\n",
      "46        1\n",
      "47        0\n",
      "48        1\n",
      "49        0\n",
      "Index(['y_label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "by = pd.read_csv('b_y.csv',names=[\"y_label\"])\n",
    "print(by)\n",
    "print(by.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['y_label'], dtype='object')\n",
      "y_label [1 0]\n"
     ]
    }
   ],
   "source": [
    "print(by.keys())\n",
    "for name in by.keys():\n",
    "    print(name,pd.unique(by[name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y_label\n",
      "0         1\n",
      "1         0\n",
      "2         1\n",
      "3         0\n",
      "4         1\n",
      "5         0\n",
      "6         1\n",
      "7         0\n",
      "8         1\n",
      "9         0\n",
      "10        1\n",
      "11        0\n",
      "12        1\n",
      "13        0\n",
      "14        1\n",
      "15        0\n",
      "16        1\n",
      "17        0\n",
      "18        1\n",
      "19        0\n",
      "20        1\n",
      "21        0\n",
      "22        1\n",
      "23        0\n",
      "24        1\n",
      "25        0\n",
      "26        1\n",
      "27        0\n",
      "28        1\n",
      "29        0\n",
      "30        1\n",
      "31        0\n",
      "32        1\n",
      "33        0\n",
      "34        1\n",
      "35        0\n",
      "36        1\n",
      "37        0\n",
      "38        1\n",
      "39        0\n",
      "40        1\n",
      "41        0\n",
      "42        1\n",
      "43        0\n",
      "44        1\n",
      "45        0\n",
      "46        1\n",
      "47        0\n",
      "48        1\n",
      "49        0\n"
     ]
    }
   ],
   "source": [
    "by_one_hot = pd.get_dummies(by)\n",
    "print(by_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  a  b  1\n",
      "1  b  a  2\n",
      "2  a  c  3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>col1_a</th>\n",
       "      <th>col1_b</th>\n",
       "      <th>col2_a</th>\n",
       "      <th>col2_b</th>\n",
       "      <th>col2_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   C  col1_a  col1_b  col2_a  col2_b  col2_c\n",
       "0  1       1       0       0       1       0\n",
       "1  2       0       1       1       0       0\n",
       "2  3       1       0       0       0       1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'A': ['a', 'b', 'a'], 'B': ['b', 'a', 'c'], 'C': [1, 2, 3]})\n",
    "print(df)\n",
    "pd.get_dummies(df, prefix=['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    p_0_0  p_0_1  p_0_2  p_0_3  p_0_4  p_0_5  p_0_6  p_0_7  p_0_8  p_0_9  \\\n",
      "0     176    224    164     66    255     79    255    156    118    196   \n",
      "1     201    113    150    201    132     22    215     99     10    231   \n",
      "2     255    127    186    255    125    107     36    227     54    125   \n",
      "3     255    214    179     53    231    242    248     11    146     87   \n",
      "4     158    134    249    174    140     23     98    194    255    137   \n",
      "5     255    133    210    220    138      1    172    246     90     43   \n",
      "6     210     43    146     12    138     26    141    195      7    133   \n",
      "7      99     67    229     79    255    133    167    255    222    248   \n",
      "8      44    250    148     10     15    163    206    150    199     10   \n",
      "9     135    255    224     27    202    129    255    165    171    252   \n",
      "10     75    177    173    203    187     97    228    113    150    123   \n",
      "11     86    202    138    194    174    208    255     43     29    155   \n",
      "12     90    148    112    147    255    129     58    254     82    255   \n",
      "13    132     76     70    125     16    147     17    255     80    255   \n",
      "14     32    134    255    157     26    130     58    169     56    190   \n",
      "15    199    238    139    172    166    255    135    191     41    134   \n",
      "16    198    216    157    169    204    205    161    187     17    100   \n",
      "17    145    113     78    235     61    123    222     72    107    254   \n",
      "18     57     76     59    194    103     54    255    178     43    126   \n",
      "19    138    255     71    171     26     51    243    179    149    255   \n",
      "20    174    240    147    107     89     31    255     96    255     46   \n",
      "21     79    211     98    255    214     70    210      9    194    153   \n",
      "22    107    255    179     16    139    255    113    201     68     27   \n",
      "23     68      6     54    255    237    147    137     49    234     49   \n",
      "24    246    200    255    169    112    232     75     59      1     75   \n",
      "25    207    252     60     73    255    137     16    116    151    212   \n",
      "26    255    119    162    109    255     24    127     47     27     32   \n",
      "27    205     28    109    114    255    114      7     83    245    208   \n",
      "28    132     66     26    111    243    205    167     49     57    255   \n",
      "29     13    137    255     64    255     83    150    127    184     80   \n",
      "30    146     35    255    215     32    153     74    120    139    119   \n",
      "31    140     88     20    183    251    255     59    255     67    185   \n",
      "32     69    174    157      1    184    171    165    241    180    201   \n",
      "33     82    255    164    165    247     88    245    142    243     38   \n",
      "34     48    184    220    190    255    150    186    239    255    217   \n",
      "35    226    228    140     70    198     58    200    188    225      0   \n",
      "36    255     42    200     37    164     12     27    255     44     41   \n",
      "37    255    249     51    215     71    232     62     75    172    255   \n",
      "38    255    221    214    255    129    255     90    198     46    105   \n",
      "39     23    161     55     76     14    140     90    161     37     55   \n",
      "40     84    200    216    247     64     57    173    191    180    165   \n",
      "41     72    255     35    183    143     40      4    252     34    255   \n",
      "42      9    143     25    199    177    147    100     99    211    173   \n",
      "43     14     95    126    253    207    214    213    255    242    255   \n",
      "44    122     41     23    175     61    239    162    210     58    164   \n",
      "45     89    213    158     26    148    108    252    216    181    255   \n",
      "46    138     93    197     95      5    170    255    255    170    255   \n",
      "47    218    213     19     94     12    148    177    234    147    226   \n",
      "48    151    244    105    170    120     83    118    221    114     20   \n",
      "49    138    105    104    147     15    100    188     63     13    180   \n",
      "\n",
      "     ...     p_39_30  p_39_31  p_39_32  p_39_33  p_39_34  p_39_35  p_39_36  \\\n",
      "0    ...          42       16      192      244      171      193      250   \n",
      "1    ...         174      190       55       65       59       57       18   \n",
      "2    ...           7       94      119      138      255      255      175   \n",
      "3    ...         187      255      167      128        5       68      171   \n",
      "4    ...          59      255       23       98       32       35       40   \n",
      "5    ...          15      167      108      143        8       64      113   \n",
      "6    ...         113      232      255      255      143      161      184   \n",
      "7    ...         107      190      105       23      145       12      162   \n",
      "8    ...          86      255       56      242      197      186      235   \n",
      "9    ...         160      254      219      219       39      238       30   \n",
      "10   ...         231       84       61       86      255      120      100   \n",
      "11   ...          21       19      163       29       73       51       11   \n",
      "12   ...          56       83      255       45      255      248       36   \n",
      "13   ...         200        6      115       29      230      178      212   \n",
      "14   ...           8      231      232      168       89      188      250   \n",
      "15   ...         255       84       51       58      135      188       25   \n",
      "16   ...         224        4      218      255       64      255       63   \n",
      "17   ...         168       27      102       66      179      225        2   \n",
      "18   ...         255      211       45      156      147      165        7   \n",
      "19   ...         255      140       37      183       98       68        3   \n",
      "20   ...         177      106       24       85       97      255      255   \n",
      "21   ...         177       86      143      123      171      208      101   \n",
      "22   ...         255       30      192        3      153       97      224   \n",
      "23   ...         221       92      200       25      194      194      227   \n",
      "24   ...         174        6      245      189      181      154       62   \n",
      "25   ...          74       21      145       85       35        9      118   \n",
      "26   ...          42        8      200      111      158       93      226   \n",
      "27   ...         233       97      237      125      121       59      143   \n",
      "28   ...         112      102        8      184      212      233      179   \n",
      "29   ...         252       74      228       21      140       48      119   \n",
      "30   ...         189      185      227      211      209      255       44   \n",
      "31   ...         153      255      135       68       51      180       34   \n",
      "32   ...         255       71      161      255       73      236      194   \n",
      "33   ...         255       34       11       29      231       41       52   \n",
      "34   ...         255       62        7      222      255      185       70   \n",
      "35   ...         255      127       84      227      224      196      173   \n",
      "36   ...         255       95       56      241      180      208      255   \n",
      "37   ...         217      202       24      143      255      255      255   \n",
      "38   ...          35      255       48      255      122       67      112   \n",
      "39   ...         243      117       57       77      255      255       21   \n",
      "40   ...         157      136       66       66      126      212      106   \n",
      "41   ...         205       46      197       93       77       55       72   \n",
      "42   ...          92      234      220      210      217      123      145   \n",
      "43   ...         170       33      177      176      233       73      140   \n",
      "44   ...           5       25      153       31      132       99      194   \n",
      "45   ...          75      166       72      255      236       29      190   \n",
      "46   ...          49      251       58       40      156      208      100   \n",
      "47   ...          43      156      246      113      174      119      153   \n",
      "48   ...         255       43      187      146       83      146      250   \n",
      "49   ...         255      178       67      221       11      250      111   \n",
      "\n",
      "    p_39_37  p_39_38  p_39_39  \n",
      "0       247      240      237  \n",
      "1       131      199      161  \n",
      "2       255       49       98  \n",
      "3       120      141       16  \n",
      "4        35      124      169  \n",
      "5       114      216      131  \n",
      "6        41      194       22  \n",
      "7       255      139       48  \n",
      "8       138      255      102  \n",
      "9       204      213       49  \n",
      "10       66       45       79  \n",
      "11      255       88      162  \n",
      "12      230      207       13  \n",
      "13      213      197      255  \n",
      "14       11       76      167  \n",
      "15      175      123      198  \n",
      "16       90       41      157  \n",
      "17       25      220      239  \n",
      "18      189      146      255  \n",
      "19       25      201       49  \n",
      "20      255      138       70  \n",
      "21      143      104      239  \n",
      "22      255      129      255  \n",
      "23      103      201       64  \n",
      "24       37      102      183  \n",
      "25      173      255      255  \n",
      "26       72       60       66  \n",
      "27       14      255      217  \n",
      "28      126      106       93  \n",
      "29      174       81      207  \n",
      "30       57      184       77  \n",
      "31      122      239      218  \n",
      "32       29      174      255  \n",
      "33        2      169      155  \n",
      "34      115       78       69  \n",
      "35      230        8      255  \n",
      "36      145      233      255  \n",
      "37      255      120      255  \n",
      "38      212       94      138  \n",
      "39      231      110       68  \n",
      "40        9      254      138  \n",
      "41        7      221      210  \n",
      "42       55       93      122  \n",
      "43      185       31      222  \n",
      "44      226      255      221  \n",
      "45      136      117      102  \n",
      "46      125       25      187  \n",
      "47      140      227       30  \n",
      "48       34       68      255  \n",
      "49       35      211      247  \n",
      "\n",
      "[50 rows x 1600 columns]\n"
     ]
    }
   ],
   "source": [
    "b_x = train_data.iloc[0:batch_size]\n",
    "print(b_x)  #老是有标签id,p_i_j等，不知输出的时候会不会带上而导致的出错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[176]\n",
      "   [224]\n",
      "   [164]\n",
      "   ..., \n",
      "   [228]\n",
      "   [225]\n",
      "   [222]]\n",
      "\n",
      "  [[ 27]\n",
      "   [241]\n",
      "   [ 19]\n",
      "   ..., \n",
      "   [ 43]\n",
      "   [255]\n",
      "   [145]]\n",
      "\n",
      "  [[193]\n",
      "   [142]\n",
      "   [ 74]\n",
      "   ..., \n",
      "   [182]\n",
      "   [213]\n",
      "   [ 26]]\n",
      "\n",
      "  ..., \n",
      "  [[218]\n",
      "   [255]\n",
      "   [140]\n",
      "   ..., \n",
      "   [166]\n",
      "   [242]\n",
      "   [178]]\n",
      "\n",
      "  [[101]\n",
      "   [  4]\n",
      "   [211]\n",
      "   ..., \n",
      "   [234]\n",
      "   [ 49]\n",
      "   [ 65]]\n",
      "\n",
      "  [[186]\n",
      "   [ 25]\n",
      "   [107]\n",
      "   ..., \n",
      "   [247]\n",
      "   [240]\n",
      "   [237]]]\n",
      "\n",
      "\n",
      " [[[201]\n",
      "   [113]\n",
      "   [150]\n",
      "   ..., \n",
      "   [ 69]\n",
      "   [117]\n",
      "   [247]]\n",
      "\n",
      "  [[187]\n",
      "   [255]\n",
      "   [232]\n",
      "   ..., \n",
      "   [ 47]\n",
      "   [205]\n",
      "   [ 76]]\n",
      "\n",
      "  [[248]\n",
      "   [  7]\n",
      "   [ 95]\n",
      "   ..., \n",
      "   [228]\n",
      "   [192]\n",
      "   [ 29]]\n",
      "\n",
      "  ..., \n",
      "  [[ 93]\n",
      "   [127]\n",
      "   [ 33]\n",
      "   ..., \n",
      "   [255]\n",
      "   [ 40]\n",
      "   [230]]\n",
      "\n",
      "  [[255]\n",
      "   [ 63]\n",
      "   [ 35]\n",
      "   ..., \n",
      "   [ 10]\n",
      "   [137]\n",
      "   [  0]]\n",
      "\n",
      "  [[118]\n",
      "   [207]\n",
      "   [170]\n",
      "   ..., \n",
      "   [131]\n",
      "   [199]\n",
      "   [161]]]\n",
      "\n",
      "\n",
      " [[[255]\n",
      "   [127]\n",
      "   [186]\n",
      "   ..., \n",
      "   [ 48]\n",
      "   [ 22]\n",
      "   [139]]\n",
      "\n",
      "  [[255]\n",
      "   [133]\n",
      "   [ 16]\n",
      "   ..., \n",
      "   [ 30]\n",
      "   [ 20]\n",
      "   [ 69]]\n",
      "\n",
      "  [[ 42]\n",
      "   [ 96]\n",
      "   [ 46]\n",
      "   ..., \n",
      "   [255]\n",
      "   [ 64]\n",
      "   [251]]\n",
      "\n",
      "  ..., \n",
      "  [[131]\n",
      "   [255]\n",
      "   [254]\n",
      "   ..., \n",
      "   [229]\n",
      "   [ 24]\n",
      "   [218]]\n",
      "\n",
      "  [[146]\n",
      "   [210]\n",
      "   [135]\n",
      "   ..., \n",
      "   [224]\n",
      "   [204]\n",
      "   [166]]\n",
      "\n",
      "  [[ 40]\n",
      "   [203]\n",
      "   [255]\n",
      "   ..., \n",
      "   [255]\n",
      "   [ 49]\n",
      "   [ 98]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[218]\n",
      "   [213]\n",
      "   [ 19]\n",
      "   ..., \n",
      "   [255]\n",
      "   [220]\n",
      "   [145]]\n",
      "\n",
      "  [[154]\n",
      "   [221]\n",
      "   [204]\n",
      "   ..., \n",
      "   [252]\n",
      "   [  3]\n",
      "   [190]]\n",
      "\n",
      "  [[ 69]\n",
      "   [ 57]\n",
      "   [114]\n",
      "   ..., \n",
      "   [229]\n",
      "   [155]\n",
      "   [251]]\n",
      "\n",
      "  ..., \n",
      "  [[134]\n",
      "   [ 11]\n",
      "   [ 73]\n",
      "   ..., \n",
      "   [ 58]\n",
      "   [147]\n",
      "   [127]]\n",
      "\n",
      "  [[255]\n",
      "   [106]\n",
      "   [210]\n",
      "   ..., \n",
      "   [158]\n",
      "   [201]\n",
      "   [255]]\n",
      "\n",
      "  [[ 20]\n",
      "   [255]\n",
      "   [178]\n",
      "   ..., \n",
      "   [140]\n",
      "   [227]\n",
      "   [ 30]]]\n",
      "\n",
      "\n",
      " [[[151]\n",
      "   [244]\n",
      "   [105]\n",
      "   ..., \n",
      "   [128]\n",
      "   [148]\n",
      "   [255]]\n",
      "\n",
      "  [[137]\n",
      "   [133]\n",
      "   [225]\n",
      "   ..., \n",
      "   [169]\n",
      "   [210]\n",
      "   [197]]\n",
      "\n",
      "  [[226]\n",
      "   [101]\n",
      "   [ 42]\n",
      "   ..., \n",
      "   [ 26]\n",
      "   [ 18]\n",
      "   [255]]\n",
      "\n",
      "  ..., \n",
      "  [[ 42]\n",
      "   [ 34]\n",
      "   [  4]\n",
      "   ..., \n",
      "   [  7]\n",
      "   [  6]\n",
      "   [ 39]]\n",
      "\n",
      "  [[255]\n",
      "   [161]\n",
      "   [ 25]\n",
      "   ..., \n",
      "   [248]\n",
      "   [141]\n",
      "   [249]]\n",
      "\n",
      "  [[145]\n",
      "   [140]\n",
      "   [182]\n",
      "   ..., \n",
      "   [ 34]\n",
      "   [ 68]\n",
      "   [255]]]\n",
      "\n",
      "\n",
      " [[[138]\n",
      "   [105]\n",
      "   [104]\n",
      "   ..., \n",
      "   [255]\n",
      "   [  2]\n",
      "   [ 42]]\n",
      "\n",
      "  [[ 34]\n",
      "   [ 57]\n",
      "   [236]\n",
      "   ..., \n",
      "   [177]\n",
      "   [210]\n",
      "   [255]]\n",
      "\n",
      "  [[  7]\n",
      "   [ 15]\n",
      "   [146]\n",
      "   ..., \n",
      "   [255]\n",
      "   [121]\n",
      "   [171]]\n",
      "\n",
      "  ..., \n",
      "  [[111]\n",
      "   [ 49]\n",
      "   [121]\n",
      "   ..., \n",
      "   [255]\n",
      "   [ 69]\n",
      "   [178]]\n",
      "\n",
      "  [[115]\n",
      "   [255]\n",
      "   [162]\n",
      "   ..., \n",
      "   [241]\n",
      "   [167]\n",
      "   [204]]\n",
      "\n",
      "  [[185]\n",
      "   [145]\n",
      "   [138]\n",
      "   ..., \n",
      "   [ 35]\n",
      "   [211]\n",
      "   [247]]]]\n"
     ]
    }
   ],
   "source": [
    "tf_x_ = tf.placeholder(tf.int32,[None,40*40]) \n",
    "x_img_ = tf.reshape(tf_x_,[-1,40,40,1])\n",
    "print(sess.run(x_img_,feed_dict={tf_x_:b_x}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n",
      "[0 1 0 0 1 1 0 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "tf_y = tf.placeholder(tf.float32,[None,2])\n",
    "y = tf.argmax(tf_y,axis = 1)\n",
    "with tf.Session() as sess1:\n",
    "    sess1.run(tf.global_variables_initializer())\n",
    "    print(sess1.run(tf_y,feed_dict={tf_y:train_labels.iloc[12:40]}))\n",
    "    print(sess1.run(tf.argmax(tf_y,axis = 1),feed_dict={tf_y:train_labels.iloc[12:40]}))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
